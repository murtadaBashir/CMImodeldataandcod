{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a29ca5-4698-4421-a66d-b32dc5916cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import product\n",
    "from karateclub import Role2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "# Load extracted DNABERT features for circRNA and miRNA\n",
    "circRNA_features = pd.read_csv('circRNA_Extractedfeatures.csv')\n",
    "miRNA_features = pd.read_csv('miRNA_Extractedfeatures.csv')\n",
    "\n",
    "# Load CMI interaction data (pairs of circRNA and miRNA)\n",
    "cmi_df = pd.read_csv('CMI9905pairs.csv')\n",
    "\n",
    "# Create a graph where circRNA and miRNA interact\n",
    "G = nx.Graph()\n",
    "for _, row in cmi_df.iterrows():\n",
    "    G.add_edge(row['miRNA'], row['circRNA'])\n",
    "\n",
    "# Create a mapping from original node labels to integers\n",
    "mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "# Get Role2Vec embeddings\n",
    "role2vec = Role2Vec()\n",
    "role2vec.fit(G)\n",
    "role2vec_embeddings = role2vec.get_embedding()\n",
    "\n",
    "# Identify node IDs that start with 'hsa_circ' and split the embeddings accordingly\n",
    "node_ids = list(mapping.keys())  # List of node IDs in their original format\n",
    "circRNA_embeddings = []\n",
    "miRNA_embeddings = []\n",
    "\n",
    "# Loop through the node IDs and corresponding embeddings\n",
    "for node_id, embedding in zip(node_ids, role2vec_embeddings):\n",
    "    if isinstance(node_id, str) and node_id.startswith('hsa_circ'):  # If the node starts with 'hsa_circ', it's a circRNA\n",
    "        circRNA_embeddings.append(embedding)\n",
    "    else:  # Otherwise, it's assumed to be miRNA or another type\n",
    "        miRNA_embeddings.append(embedding)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "circRNA_embeddings = np.array(circRNA_embeddings)\n",
    "miRNA_embeddings = np.array(miRNA_embeddings)\n",
    "\n",
    "# Check the shape of circRNA_features and circRNA_embeddings\n",
    "print(f\"circRNA features shape: {circRNA_features.shape}\")\n",
    "print(f\"circRNA embeddings shape: {circRNA_embeddings.shape}\")\n",
    "\n",
    "# Align circRNA features and embeddings by filtering based on the smaller size\n",
    "min_circRNA_size = min(len(circRNA_features), len(circRNA_embeddings))\n",
    "\n",
    "# Adjust both to have the same number of rows\n",
    "aligned_circRNA_features = circRNA_features.iloc[:min_circRNA_size]\n",
    "aligned_circRNA_embeddings = circRNA_embeddings[:min_circRNA_size]\n",
    "\n",
    "# Concatenate circRNA features and embeddings\n",
    "X_circRNA = np.hstack([aligned_circRNA_features, aligned_circRNA_embeddings])\n",
    "\n",
    "# Check the shape of the concatenated data\n",
    "print(f\"X_circRNA shape after alignment: {X_circRNA.shape}\")\n",
    "\n",
    "# Align miRNA features and embeddings by filtering them based on the smaller size\n",
    "min_miRNA_size = min(len(miRNA_features), len(miRNA_embeddings))\n",
    "\n",
    "# Adjust both to have the same number of rows\n",
    "aligned_miRNA_features = miRNA_features.iloc[:min_miRNA_size]\n",
    "aligned_miRNA_embeddings = miRNA_embeddings[:min_miRNA_size]\n",
    "\n",
    "# Concatenate aligned miRNA features and embeddings\n",
    "X_miRNA = np.hstack([aligned_miRNA_features, aligned_miRNA_embeddings])\n",
    "\n",
    "# Generate all possible circRNA-miRNA pairs\n",
    "all_pairs = list(product(circRNA_features.index, aligned_miRNA_features.index))\n",
    "\n",
    "# Filter out the positive pairs (those already known to interact from the CMI dataset)\n",
    "positive_pairs = set((mapping[row['miRNA']], mapping[row['circRNA']]) for _, row in cmi_df.iterrows())\n",
    "all_pairs_set = set(all_pairs)\n",
    "\n",
    "# Get negative pairs by subtracting positive pairs from all pairs\n",
    "negative_pairs = list(all_pairs_set - positive_pairs)\n",
    "\n",
    "# Randomly sample the same number of negative pairs as positive pairs\n",
    "np.random.shuffle(negative_pairs)\n",
    "negative_pairs = negative_pairs[:len(positive_pairs)]\n",
    "\n",
    "# Map the circRNA and miRNA indices back to their original labels\n",
    "negative_pairs_mapped = [(list(mapping.keys())[circ_idx], list(mapping.keys())[miRNA_idx]) for circ_idx, miRNA_idx in negative_pairs]\n",
    "\n",
    "# Create DataFrame for negative samples\n",
    "negative_df = pd.DataFrame(negative_pairs_mapped, columns=['miRNA', 'circRNA'])\n",
    "negative_df['interaction'] = 0  # Label these as non-interaction\n",
    "\n",
    "# Add label 1 for positive pairs\n",
    "cmi_df['interaction'] = 1\n",
    "\n",
    "# Combine positive and negative samples\n",
    "interaction_df = pd.concat([cmi_df[['miRNA', 'circRNA', 'interaction']], negative_df], ignore_index=True)\n",
    "\n",
    "# Create feature vectors for each circRNA-miRNA pair\n",
    "valid_rows = []\n",
    "X = []\n",
    "\n",
    "for index, row in interaction_df.iterrows():\n",
    "    miRNA_id = row['miRNA']\n",
    "    circRNA_id = row['circRNA']\n",
    "    \n",
    "    if circRNA_id in mapping and miRNA_id in mapping:\n",
    "        miRNA_idx = mapping[miRNA_id]\n",
    "        circRNA_idx = mapping[circRNA_id]\n",
    "        \n",
    "        if miRNA_idx < X_miRNA.shape[0] and circRNA_idx < X_circRNA.shape[0]:\n",
    "            combined_features = np.hstack([X_miRNA[miRNA_idx], X_circRNA[circRNA_idx]])\n",
    "            X.append(combined_features)\n",
    "            valid_rows.append(index)\n",
    "\n",
    "# Convert the list of feature vectors to numpy array\n",
    "X = np.array(X)\n",
    "\n",
    "# Extract the matching y labels from valid rows\n",
    "y = interaction_df.loc[valid_rows]['interaction'].values\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define GAT model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels=64, heads=2):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define training function\n",
    "def train(model, optimizer, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    logits = model(data)\n",
    "    y_pred = logits[data.test_mask].max(1)[1].cpu().numpy()\n",
    "    y_true = data.y[data.test_mask].cpu().numpy()\n",
    "    y_probs = logits[data.test_mask][:, 1].cpu().detach().numpy()  # probabilities for class 1\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_probs)\n",
    "    \n",
    "    # Calculate AUPR\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_probs)\n",
    "    aupr = auc(recall_curve, precision_curve)\n",
    "\n",
    "    return accuracy, precision, recall, f1, roc_auc, aupr, y_true, y_pred, y_probs\n",
    "\n",
    "# Initialize dictionaries to store FPR, TPR, Precision, and Recall for each fold\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "\n",
    "# K-Fold Cross-Validation Setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_scaled)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "    \n",
    "    # Create train and test masks\n",
    "    train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "    test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "    train_mask[train_index] = True\n",
    "    test_mask[test_index] = True\n",
    "    \n",
    "    # Prepare PyTorch Geometric data object\n",
    "    edge_index = torch.tensor(list(zip(*G.edges)), dtype=torch.long)\n",
    "    x = torch.tensor(X_scaled, dtype=torch.float)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, y=y_tensor)\n",
    "    data.train_mask = train_mask\n",
    "    data.test_mask = test_mask\n",
    "    \n",
    "    # Initialize model, optimizer\n",
    "    model = GAT(in_channels=x.shape[1], out_channels=2).to(device)\n",
    "    data = data.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "    # Train model\n",
    "    for epoch in range(200):\n",
    "        loss = train(model, optimizer, data)\n",
    "    \n",
    "    # Evaluate model on the test set\n",
    "    accuracy, precision, recall, f1, roc_auc, aupr, y_true, y_pred, y_probs = evaluate(model, data)\n",
    "    print(f'Fold {fold + 1} -- Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUROC: {roc_auc:.4f}, AUPR: {aupr:.4f}')\n",
    "    \n",
    "    # Store metrics for each fold\n",
    "    fold_metrics.append({\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'aupr': aupr\n",
    "    })\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    fpr_dict[fold] = fpr\n",
    "    tpr_dict[fold] = tpr\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_probs)\n",
    "    precision_dict[fold] = precision_curve\n",
    "    recall_dict[fold] = recall_curve\n",
    "\n",
    "# Plot all ROC curves on one figure\n",
    "plt.figure()\n",
    "for fold in range(5):\n",
    "    plt.plot(fpr_dict[fold], tpr_dict[fold], lw=2, label=f'Fold {fold + 1} ROC curve (AUC = {auc(fpr_dict[fold], tpr_dict[fold]):.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Each Fold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot all PR curves on one figure\n",
    "plt.figure()\n",
    "for fold in range(5):\n",
    "    plt.plot(recall_dict[fold], precision_dict[fold], lw=2, label=f'Fold {fold + 1} PR curve (AUPR = {auc(recall_dict[fold], precision_dict[fold]):.4f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves for Each Fold')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "# Aggregate metrics across folds\n",
    "avg_metrics = {metric: np.mean([f[metric] for f in fold_metrics]) for metric in fold_metrics[0].keys()}\n",
    "std_metrics = {metric: np.std([f[metric] for f in fold_metrics]) for metric in fold_metrics[0].keys()}\n",
    "\n",
    "print(f'Average Metrics across 5 folds:')\n",
    "print(f'Accuracy: {avg_metrics[\"accuracy\"]:.4f}, Precision: {avg_metrics[\"precision\"]:.4f}, Recall: {avg_metrics[\"recall\"]:.4f}, F1: {avg_metrics[\"f1\"]:.4f}, AUROC: {avg_metrics[\"roc_auc\"]:.4f}, AUPR: {avg_metrics[\"aupr\"]:.4f}')\n",
    "print(f'Standard Deviation across 5 folds:')\n",
    "print(f'Accuracy: {std_metrics[\"accuracy\"]:.4f}, Precision: {std_metrics[\"precision\"]:.4f}, Recall: {std_metrics[\"recall\"]:.4f}, F1: {std_metrics[\"f1\"]:.4f}, AUROC: {std_metrics[\"roc_auc\"]:.4f}, AUPR: {std_metrics[\"aupr\"]:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
